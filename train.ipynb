{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58431419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 10:43:38.478197: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d82fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7c0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full = pd.read_csv('data/train.csv', dtype={'Id': str})\n",
    "df_train_full['filename'] = 'data/images/' + df_train_full['Id'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403b6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train_full in train(0.8) and val(0.2)\n",
    "val_cutoff = int(len(df_train_full) * 0.8)\n",
    "df_train = df_train_full[:val_cutoff]\n",
    "df_val = df_train_full[val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835a9993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4447 validated image filenames belonging to 6 classes.\n",
      "Found 1112 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# ### DATA AUGMENTATION ###\n",
    "input_size = 299\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    #vertical_flip=True,\n",
    "    rotation_range=5.0,\n",
    "    fill_mode='nearest',\n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1\n",
    "    #channel_shift_range=0.2\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col='filename',\n",
    "    y_col='label',\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0ed6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 10:43:58.224249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.231318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.231936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.232872: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 10:43:58.233245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.233908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.234477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.898691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.899317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.899876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-22 10:43:58.900403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(input_size, input_size, 3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(input_size, input_size, 3))\n",
    "    \n",
    "base = base_model(inputs, training=False)\n",
    "vector = keras.layers.GlobalAveragePooling2D()(base)\n",
    "\n",
    "inner = keras.layers.Dense(100, activation='relu')(vector)\n",
    "drop = keras.layers.Dropout(rate=0.5)(inner)\n",
    "\n",
    "outputs = keras.layers.Dense(6)(drop)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c95d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 10:44:12.759756: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-12-22 10:44:13.431253: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-22 10:44:13.431796: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-22 10:44:13.431843: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-12-22 10:44:13.432455: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-22 10:44:13.432532: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 149s 1s/step - loss: 0.3636 - accuracy: 0.8826 - val_loss: 0.1472 - val_accuracy: 0.9532\n",
      "Epoch 2/5\n",
      "139/139 [==============================] - 137s 985ms/step - loss: 0.1784 - accuracy: 0.9413 - val_loss: 0.1235 - val_accuracy: 0.9577\n",
      "Epoch 3/5\n",
      "139/139 [==============================] - 138s 989ms/step - loss: 0.1457 - accuracy: 0.9521 - val_loss: 0.1257 - val_accuracy: 0.9559\n",
      "Epoch 4/5\n",
      "139/139 [==============================] - 137s 988ms/step - loss: 0.1247 - accuracy: 0.9606 - val_loss: 0.1210 - val_accuracy: 0.9523\n",
      "Epoch 5/5\n",
      "139/139 [==============================] - 136s 977ms/step - loss: 0.1197 - accuracy: 0.9645 - val_loss: 0.1164 - val_accuracy: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab4063fee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(train_generator, epochs=5, verbose=1, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffbe9312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96043, saving model to kitchenware_final_01_0.960.h5\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.96043\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.96043 to 0.96133, saving model to kitchenware_final_03_0.961.h5\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.96133 to 0.96313, saving model to kitchenware_final_04_0.963.h5\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.96313 to 0.96673, saving model to kitchenware_final_05_0.967.h5\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.96673\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.96673\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.96673\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.96673 to 0.96853, saving model to kitchenware_final_09_0.969.h5\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.96853 to 0.96942, saving model to kitchenware_final_10_0.969.h5\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "#unfreeze the last 32 layers of the base model for doing a partial fine tuning \n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-32]:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Low learning rate to avoid destruction of the learned weights\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"kitchenware_final_{epoch:02d}_{val_accuracy:.3f}.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        mode='min', \n",
    "        verbose=1, \n",
    "        patience=5\n",
    "    )\n",
    "]\n",
    "\n",
    "history_6 = model.fit(train_generator, epochs=50, verbose=0, validation_data=val_generator, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44155765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[-4.701105   1.4049903 -3.1885097 14.954982  -5.150577   2.9660013]]\n"
     ]
    }
   ],
   "source": [
    "#predictions for a single image (useful for testing service deployment)\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "\n",
    "img_path = 'data/images/3962.jpg'\n",
    "\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "#print('Keras Predicted:', decode_predictions(preds, top=3)[0])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa503b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv', dtype={'Id': str})\n",
    "df_test['filename'] = 'data/images/' + df_test['Id'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cdc1c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3808 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "#class_mode = 'input'means that in the label arrays that are returned each label will be will be images identical to input images\n",
    "#useful for fitting autoencoders\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    x_col='filename',\n",
    "    class_mode='input',\n",
    "    #target_size=(150, 150),\n",
    "    target_size=(input_size, input_size),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eac60f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 58s 478ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b16045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(list(train_generator.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac34624",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classes[y_pred.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881e389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
